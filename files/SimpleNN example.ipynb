{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdb5b888",
   "metadata": {},
   "source": [
    "# Neural Networks in PyTorch\n",
    "## What is a neural network?\n",
    "You can think of a neural network as a simple function that takes an input and produces an output. In this example, we will focus on a simple MLP (Multi Layer Perceptron). This is a modern feed forward neural network with the following conditions:\n",
    "1. Fully Connected Layers.\n",
    "2. At least one hidden layer.\n",
    "\n",
    "### Input Layer\n",
    "This is where your data enters the network. The number of neurons in this layer corresponds to the number of features in your dataset.\n",
    "\n",
    "### Hidden Layers\n",
    "These are the layers between the input and output layers. They perform most of the computational work, transforming the input data through a series of mathematical operations. Each neuron in a hidden layer takes a weighted sum of the outputs from the previous layer, adds a bias term, and then passes the result through an activation function.  The activation function is key because it introduces non-linearity, allowing the network to learn complex patterns that a simple linear model couldn't.\n",
    "\n",
    "### Output Layer\n",
    "This is the final layer that produces the network's prediction. The number of neurons here depends on the problem you're trying to solve (e.g., one neuron for binary classification, multiple neurons for multi-class classification).\n",
    "NOTE: Most output layers will pass the output given by the network into a *softmax* function to provide probabilities for each class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2220ddae",
   "metadata": {},
   "source": [
    "## Loading our Data\n",
    "In the following code, we will get our dataset from the torchvision library. This dataset has a ton of images that we can use to train our network. [MNIST](https://docs.pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html)\n",
    "\n",
    "### Transformer\n",
    "The raw images are not readable by our model so we need to convert them into PyTorch tensors before we do anything. We can do this by using torchvision's ToTensor() method (torchvision.transforms.ToTensor()). \n",
    "```py\n",
    "from torchvision import transforms\n",
    "transformer = transforms.Compose([\n",
    "    transforms.ToTensor(), # Convert the image to a PyTorch Tensor\n",
    "])\n",
    "```\n",
    "Along with converting the images into PyTorch Tensors, the ToTensor method will also scale the pixel values from [0, 255] to [0.0, 1.0]\n",
    "We use transforms.Compose here so we can chain together multiple transformers in the future (like transforms.Normalize()).\n",
    "\n",
    "Next, we import our datasets from torchvision.datasets. This dataset has a pre-defined split: 60,000 images for the `Train=True` and 10,000 for the `Train=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "294e257c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\hp\\anaconda3\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch) (2023.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torchvision in c:\\users\\hp\\anaconda3\\lib\\site-packages (0.23.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: torch==2.8.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torchvision) (2.8.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch==2.8.0->torchvision) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch==2.8.0->torchvision) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch==2.8.0->torchvision) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch==2.8.0->torchvision) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch==2.8.0->torchvision) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch==2.8.0->torchvision) (2023.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch==2.8.0->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jinja2->torch==2.8.0->torchvision) (2.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch\n",
    "%pip install torchvision\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms, datasets # Contains our MNIST dataset and a transformer to convert the PIL images into PyTorch Tensors.\n",
    "\n",
    "transformer = transforms.Compose([\n",
    "    transforms.ToTensor(), # Convert the image to a PyTorch Tensor\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    root='./data', \n",
    "    train=True, \n",
    "    transform=transformer, \n",
    "    download=True\n",
    ")\n",
    "\n",
    "test_dataset = datasets.MNIST(\n",
    "    root='./data', \n",
    "    train=False, \n",
    "    transform=transformer, \n",
    "    download=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a3bd0a",
   "metadata": {},
   "source": [
    "## Data Loader\n",
    "### What is a Data Loader?\n",
    "A DataLoader is an iterable that wraps a Dataset and provides an efficient way to load and process data for training or inference in machine learning models.\n",
    "It can shuffle our data and split them into batches. \n",
    "\n",
    "The `shuffle=True` parameter is very important while we train as shuffling our training data ensures that in each epoch—one complete pass through the entire training dataset—our model sees the images in a different, random order. This prevents things like `Memorization` or `Order Bias`\n",
    "\n",
    "## Why Batching?\n",
    "Batching is used to balance computational efficiency with the model's performance. We use mini-batching here as it is a compromise between training on the whole dataset at once ([batch gradient descen](https://zilliz.com/glossary/batch-gradient-descent)) and training on individual data points ([stochastic gradient descent](https://www.geeksforgeeks.org/machine-learning/ml-stochastic-gradient-descent-sgd/)). \n",
    "\n",
    "### Pros of Mini-Batching\n",
    "1. Computational Efficiency: It is much faster than full-batching and requires less memory.\n",
    "\n",
    "2. Training Stability: It provides a more stable and representative gradient than pure SGD, leading to a more reliable training process.\n",
    "\n",
    "3. Escaping Local Minima: The inherent noise in the gradient can actually be a good thing, helping the model to avoid getting stuck in a shallow \"local minimum\" and find a better solution in the loss landscape.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "448acc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Defining a batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8956e686",
   "metadata": {},
   "source": [
    "## Creating our Neural Network\n",
    "The following code shows us how we can structure our network. In our `__init__` method, we define the layers of our neural network, including a flattening layer and a stack of linear layers with activation functions.\n",
    "\n",
    "### Inside of our initalizer (\\_\\_init\\_\\_)\n",
    "#### Flatten\n",
    "The nn.Flatten layer transforms the 2D input tensor (28x28) into a 1D vector (784 features), preparing it for the linear layers.\n",
    "\n",
    "#### Layers\n",
    "We use nn.Sequential to create a container for a linear stack of layers. The ReLU (Rectified Linear Unit) activation function introduces non-linearity to the network, allowing it to learn complex, non-linear mappings.\n",
    "1. The first linear layer takes a 784-dimensional input and projects it into a 512-dimensional feature space.\n",
    "2. The second linear layer further transforms the 512 features into a 256-dimensional space.\n",
    "3. The final linear layer, or \"output layer,\" projects the features down to 10 dimensions, corresponding to the 10 digit classes (0-9). These raw outputs are known as \"logits.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3426cc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten() # Flattens the 28x28 image into a 784-dimensional vector\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512), # First linear layer\n",
    "            nn.ReLU(), # Activation function\n",
    "            nn.Linear(512, 256), # Second linear layer\n",
    "            nn.ReLU(), # Activation function\n",
    "            nn.Linear(256, 10) # Output layer\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x) # Flatten the input\n",
    "        logits = self.linear_relu_stack(x) # Pass through the linear_relu_stack\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cba07bd",
   "metadata": {},
   "source": [
    "## Forward Pass\n",
    "1. First we must create an instance of our model. \n",
    "2. Next, we need to get our next batch. We use our training DataLoader to get a single batch of images and their corresponding labels. \n",
    "3. Finally, we pass in our images into our model. PyTorch will automatically call the forward() method we have created earlier. This method returns our logits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d0b5f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the logits tensor: torch.Size([64, 10])\n",
      "Sample logits for first image:\n",
      "tensor([ 0.0765,  0.0350, -0.0983,  0.0425, -0.0550,  0.0564, -0.0206, -0.0030,\n",
      "        -0.0416, -0.0777], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the model\n",
    "model = SimpleNN()\n",
    "\n",
    "# Get a single batch of images and labels from the training data loader\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "# Perform the forward pass to get the logits\n",
    "logits = model(images)\n",
    "\n",
    "# Print the shape of the output\n",
    "print(f\"Shape of the logits tensor: {logits.shape}\")\n",
    "print(f\"Sample logits for first image:\\n{logits[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f85aa0f",
   "metadata": {},
   "source": [
    "## Loss Function\n",
    "A loss function is a mathematical function that measures the discrepancy between the network's predictions and and true labels. \\\n",
    "Since our model has multiple outputs, a multi-class classification network, we will use the Cross-Entropy Loss function. \n",
    "### Cross-Entropy Loss Function\n",
    "`nn.CrossEntropyLoss` compines two key operations in one efficient function:\n",
    "#### Softmax\n",
    "It first applies the softmax function to the network's logits (raw output). This converts the logits into a set of probabilities that will sum up to 1. The highest logit will correspond to the class with the highest probability. \\\n",
    "Softmax formula: $$ P(y_i) = \\frac{e^{z_i}}{\\sum_{j=1}^{K} e^{z_j}} $$\n",
    "#### Negative Log likelihood\n",
    "It then calculates the negative log likelihood of the true class. This will heavily penalize the model when it is very confident (assigns a high probability) about a wrong prediction. \\\n",
    "NLL formula: $$ L_{NLL} = -log(p_i) $$\n",
    "where $i$ is the true class and $p_i$ is the probability of the true class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f240cd86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss value: 2.298157215118408\n"
     ]
    }
   ],
   "source": [
    "# Define the loss function\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# Calculate the loss\n",
    "loss = loss_function(logits, labels)\n",
    "\n",
    "print(f\"Loss value: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9403012",
   "metadata": {},
   "source": [
    "## Optimizer\n",
    "### What is an Optimizer?\n",
    "An optimizer is an algorithm that adjusts the model's weights and biases to reduce the loss. Think of the loss function as a measure of the \"error\" or \"cost,\" and the optimizer as the engine that uses that information to navigate a \"loss landscape\" to find the lowest point. Some examples of Optimizers are Adam, RMSprop, Adagrad, and multiple versions of Gradient Descent. \\\n",
    "\n",
    "Lets use Adam for this example. \n",
    "### Adam (Optimizer)\n",
    "Adam, which stands for Adaptive Moment Estimation, is an advanced optimization algorithm used to train neural networks. Adam is a more sophisticated and often times more effective model then stochastic gradient descent. Adam works by dynamically changing the learning rate for each of the model's parameters, rather than a fixed learning rate for all of them. You can learn more about gradient descent optimization algorithms [here](https://arxiv.org/pdf/1609.04747). \\\n",
    "NOTE: `model.parameters()` returns an iterator that gives the optimizer access to the model's trainable tensors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a09582c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Set the starting learning rate (hyperparameter)\n",
    "# This is the maximum learning rate and acts as an Upper Bound for the learning rates.\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e229936d",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "Now that we have set up all the components we need to train our model, we can combine them all to create our training loop. \\\n",
    "The Training Loop is an iterative process that runs for a number of `epochs`. An epoch is one full pass through the entire training dataset.\n",
    "Here's a breakdown of the four key steps that happen in each iteration of the loop:\n",
    "1. Forward Pass: We pass a batch of data through the model to get predictions.\n",
    "2. Loss Calculation: We compare the predictions to the actual labels using our `loss_function`.\n",
    "3. Backpropagation: We call `loss.backward()` to compute the gradients. PyTorch handles this automatically.\n",
    "4. Parameter Update: We call `optimizer.step()` to update the model's weights and biases using the gradients.\n",
    "\n",
    "NOTE: It's also crucial to zero out the gradients before each backward pass. We do this by calling `optimizer.zero_grad()`. This is because PyTorch accumulates gradients by default. If we don't zero them out, the gradients from the previous batch would be added to the gradients of the current batch, leading to incorrect updates. \\\n",
    "This is manually done as to allow for more flexable training strategies such as Gradient Accumulation and Multi-Task Learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f08de282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.23829017599711\n",
      "Epoch 2, Loss: 0.08969508984914498\n",
      "Epoch 3, Loss: 0.0576080125368097\n",
      "Epoch 4, Loss: 0.043796712890511125\n",
      "Epoch 5, Loss: 0.034099964722583906\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter\n",
    "# Define the number of epochs\n",
    "epochs = 5\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    running_loss = 0.0 # To monitor progress and debugging. This should eventually flatten out\n",
    "    for inputs, labels in train_loader:\n",
    "        # Zero out the gradients \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward Pass\n",
    "        logits = model(inputs)\n",
    "        loss = loss_function(logits, labels)\n",
    "\n",
    "        # Backward Pass (backpropagation)\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print the average loss for this epoch\n",
    "    print(f\"Epoch {epoch}, Loss: {running_loss / len(train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bc3a8f",
   "metadata": {},
   "source": [
    "## Chain of Communication \n",
    "For understanding, this is the chain of communication:\n",
    "1. `model and DataLoader`: The `DataLoader` provides batches of data to the model's forward method.\n",
    "\n",
    "2. `loss and model`: The `loss_function` takes the model's raw output (logits) and compares it to the true labels.\n",
    "\n",
    "3. `loss and PyTorch's Autograd`: Calling `loss.backward()` is the key trigger. PyTorch's automatic differentiation engine (`Autograd`) takes over. It traces the entire computation from the final loss value back to the initial input parameters.\n",
    "\n",
    "4. `Autograd and model's parameters`: As it traces back, `Autograd` computes the gradient for each parameter and populates the `.grad` attribute for that parameter's tensor.\n",
    "\n",
    "5. `optimizer and model's parameters`: The `optimizer` was already given a reference to all the parameters. When `optimizer.step()` is called, it accesses the now-populated `.grad` attributes and updates the parameters' values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172dde8b",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "After the training loop is complete, your neural network has learned and its weights have been adjusted to make better predictions. This is great for the training data, but the true test of a model's performance is how well it works on data it has never seen before. We do this by evaluating the model on our separate test dataset.\n",
    "\n",
    "The evaluation process is different from training because our goal is just to measure performance, not to continue learning. Therefore, we do not update the model's parameters, which means we do not need the loss function, backpropagation, or the optimizer.\n",
    "\n",
    "The following code is a high-level overview of the evaluation process:\n",
    "\n",
    "`model.eval()`: This command tells PyTorch that the model is now in evaluation mode. This is very important because certain layers, like Dropout and BatchNorm, behave differently during evaluation than they do during training.\n",
    "\n",
    "`with torch.no_grad()`: This is a context manager that temporarily disables gradient calculation. Since we are not training, we don't need to compute gradients, and using this block saves memory and speeds up computations.\n",
    "\n",
    "`Looping through the test_loader`: We use the test_loader to iterate through all the test images in batches.\n",
    "\n",
    "`torch.max(outputs.data, 1)`: For each batch, we perform a forward pass to get the logits. Then, we use torch.max to find the index of the highest logit for each image. This index is our model's final prediction for that image.\n",
    "\n",
    "`Calculating Accuracy`: Finally, we compare the model's predictions to the true labels to calculate the accuracy. Accuracy is a simple and intuitive metric that tells us the percentage of test images that the model correctly classified.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5c61eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 10,000 test images: 97.30%\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Disable gradient calculation\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        # Get the predicted class\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy of the model on the 10,000 test images: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15699613",
   "metadata": {},
   "source": [
    "## Lets try some other network architectures\n",
    "Lets create a network with only one hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a29553ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleLayerNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten() # Flattens the 28x28 image into a 784-dimensional vector\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 256), # First linear layer\n",
    "            nn.ReLU(), # Activation function\n",
    "            nn.Linear(256, 10) # Output layer\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a943e365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1's training loss: 288.5349732283503\n",
      "Epoch 2's training loss: 122.41327644325793\n",
      "Epoch 3's training loss: 80.539859585464\n",
      "Epoch 4's training loss: 58.42187776044011\n",
      "Epoch 5's training loss: 43.51963080186397\n"
     ]
    }
   ],
   "source": [
    "# Create our model\n",
    "single_layer_model = SingleLayerNN()\n",
    "\n",
    "# Create our loss function\n",
    "single_layer_loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# Create our ADAM Optimizer\n",
    "single_layer_optimizer = optim.Adam(single_layer_model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    running_loss = 0.0\n",
    "    for index, (inputs, labels) in enumerate(train_loader):\n",
    "        # Zero out the gradients \n",
    "        single_layer_optimizer.zero_grad()\n",
    "\n",
    "        # Forward Pass\n",
    "        logits = single_layer_model(inputs)\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = single_layer_loss_function(logits, labels)\n",
    "\n",
    "        # Backward Pass (backpropagation)\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the weights\n",
    "        single_layer_optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch {epoch}\\'s training loss: {running_loss}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6b91538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 10,000 test images: 97.78%\n"
     ]
    }
   ],
   "source": [
    "single_layer_model.eval()  # Set the model to evaluation mode\n",
    "single_layer_correct = 0\n",
    "single_layer_total = 0\n",
    "\n",
    "# Disable gradient calculation\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = single_layer_model(images)\n",
    "        # Get the predicted class\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        single_layer_total += labels.size(0)\n",
    "        single_layer_correct += (predicted == labels).sum().item()\n",
    "\n",
    "single_layer_accuracy = 100 * single_layer_correct / single_layer_total\n",
    "print(f'Accuracy of the model on the 10,000 test images: {single_layer_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64a3100",
   "metadata": {},
   "source": [
    "## Advantages of More Layers and Neurons\n",
    "More hidden layers and neurons increase the network's capacity. This is a major advantage for complex tasks.\n",
    "\n",
    "### Learning Complex Patterns\n",
    "A deeper and wider network has more trainable parameters (weights and biases). This gives the model the flexibility to learn and represent non-linear relationships in the data that a simpler model cannot.\n",
    "\n",
    "### Improved Performance\n",
    "On large and complex datasets, a higher-capacity network can often achieve higher accuracy and outperform a simpler network because it is better equipped to capture all the variations in the data.\n",
    "\n",
    "## Disadvantages of More Layers and Neurons\n",
    "A network with too much capacity can lead to a significant problem called overfitting.\n",
    "\n",
    "### Overfitting\n",
    "This occurs when a model learns the training data and its random noise too well. Instead of learning the general patterns, the network essentially \"memorizes\" the specific examples it has seen. As a result, the model performs exceptionally well on the training data but fails to generalize to new, unseen data, leading to poor performance on the test set.\n",
    "\n",
    "### Computational Cost\n",
    "Deeper networks with more neurons require significantly more memory and computational resources for training, which can be a limitation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
